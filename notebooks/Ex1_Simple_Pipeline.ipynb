{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Build a pipeline using Peak Performance's convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "from pathlib import Path\n",
    "from peak_performance import pipeline as pl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, store the path to a folder containing only the raw data you want to analyze in the `path_raw_data` variable.  \n",
    "You can use a string with a preceding `r` so that the backslashes are recognized correctly or the `Path` method from the `pathlib` package for an OS-independent alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the absolute path to the raw data files (as a str or a Path object), e.g. to the provided example files\n",
    "\n",
    "# path_raw_data = r\"C:\\Users\\niesser\\Desktop\\Local GitLab Repositories\\peak-performance\\example\"\n",
    "path_raw_data = Path(r\"C:\\Users\\niesser\\Desktop\\Local GitLab Repositories\\peak-performance\\example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, use the specified path as an argument for the `detect_raw_data()` function which returns a list of all files of the given data type in the given path.  \n",
    "If you don't specify a data type, the default is `.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1t1R1Part2_110_109.9_110.1.npy', 'A1t1R1Part2_111_109.9_110.1.npy', 'A1t1R1Part2_111_110.9_111.1.npy', 'A1t1R1Part2_112_110.9_111.1.npy', 'A1t1R1Part2_112_111.9_112.1.npy', 'A2t2R1Part1_132_85.9_86.1.npy', 'A4t4R1Part2_137_72.9_73.1.npy']\n"
     ]
    }
   ],
   "source": [
    "# obtain a list of all raw data file names (including their data type)\n",
    "raw_data_files = pl.detect_raw_data(path_raw_data)\n",
    "print(raw_data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the list of files, provide the following information which is necessary for the pipeline:  \n",
    "1. A dictionary `double_peak` containing the file names (including data type) as keys and Boolean values depending on whether the file contains a __single peak (False)__ or __double peak (True)__.  \n",
    "    \n",
    "2. A Boolean `pre_filtering`. Choose whether you want to filter out obvious false positive signals before sampling to save computation time (__True__) or not (__False__). If \"False\" was chosen, skip 3 - 6.\n",
    "    \n",
    "    3. If `pre_filtering` was set to __True__: Provide a dictionary `retention_time_estimate` containing the file names (including data type) as keys and a rough retention time estimate of the compound pertaining to each given raw data file.  \n",
    "  \n",
    "    4. If `pre_filtering` was set to __True__: A float or integer `peak_width_estimate` containing a rough estimate of the average peak width of your LC-MS/MS method (in minutes).  \n",
    "  \n",
    "    5. If `pre_filtering` was set to __True__: A float or integer `minimum_sn` defining a lower threshold of the signal-to-noise ratio which has to be exceed for a signal to be accepted as a peak during pre-filtering. \n",
    "  \n",
    "  6. A Boolean `plotting`. Choose whether to create plots (__True__) or not (__False__). In the latter case, the pipeline will only yield the Excel data report sheet with all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the previously acquired list raw_data_files, this is the easiest way to define the double_peak dictionary\n",
    "# the list with the Booleans needs to be in the same order as raw_data_files\n",
    "double_peak = dict(zip(raw_data_files, 5*[False] + [True] + [False]))       \n",
    "\n",
    "pre_filtering = True                \n",
    "retention_time_estimate = dict(zip(raw_data_files, 5*[26.2] + [(11.7, 12.5)] + [26.2]))    \n",
    "peak_width_estimate = 1             \n",
    "minimum_sn = 5                      \n",
    "\n",
    "plotting = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When triggering the pipeline, a folder for the results named after the current data and time will be created automatically in the directory with the raw data files.  \n",
    "The `%%capture --no-display` at the beginning of the cell merely suppresses most of the output within this notebook and has no connection to the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "pl.pipeline(path_raw_data = path_raw_data,\n",
    "    raw_data_file_format = \".npy\",\n",
    "    pre_filtering = pre_filtering,\n",
    "    double_peak = double_peak,\n",
    "    retention_time_estimate = retention_time_estimate,\n",
    "    peak_width_estimate = peak_width_estimate,\n",
    "    minimum_sn = minimum_sn,\n",
    "    plotting = plotting,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pm530",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
